{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The following lines enable automatic reloading of modules in an IPython/Jupyter environment.\n",
                "# They work exactly like the commented lines below, but avoid errors when not running in such an environment.\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n",
                "\n",
                "try:\n",
                "    # Only defined inside IPython/Jupyter\n",
                "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
                "    get_ipython().run_line_magic(\"autoreload\", \"2\")\n",
                "except (NameError, AttributeError):\n",
                "    # Not running in IPython â†’ just ignore\n",
                "    pass\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initializing answer variable\n",
                "answer = {}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "DWr6cvb9pS3J"
            },
            "outputs": [],
            "source": [
                "# Some libs that we will use\n",
                "import torch\n",
                "import random\n",
                "import numpy as np\n",
                "import json_tricks\n",
                "import lovely_tensors as lt\n",
                "\n",
                "# Making tensor printouts better\n",
                "lt.monkey_patch()\n",
                "\n",
                "# Adding sources to the pythonpath\n",
                "import sys\n",
                "root_path = '../../../..'\n",
                "sys.path.append(root_path)\n",
                "\n",
                "import dotenv\n",
                "dotenv.load_dotenv(dotenv.find_dotenv(root_path + '/.env'))\n",
                "\n",
                "# Importing sources of our project\n",
                "import src\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 0: Prepare the environment"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "src.utils.seed.seed_all(0)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 1: Prepare the data"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "MqGQWTDIpS3R"
            },
            "outputs": [],
            "source": [
                "MNIST_train = ...\n",
                "MNIST_valid = ...\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check that the data is prepared:"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "vv_Lz7PYpS3U"
            },
            "outputs": [],
            "source": [
                "train_sample = MNIST_train[0]\n",
                "valid_sample = MNIST_valid[0]\n",
                "\n",
                "X_train = train_sample['image']\n",
                "X_valid = valid_sample['image']\n",
                "y_train = train_sample['label']\n",
                "y_valid = valid_sample['label']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 35
                },
                "colab_type": "code",
                "id": "hMhsAedlrQF5",
                "outputId": "ae08bd21-79ff-48da-9886-48996a178110"
            },
            "outputs": [],
            "source": [
                "## This checks are for dataset verification\n",
                "answer['X_train.dtype'] = str(X_train.dtype)\n",
                "answer['y_train.dtype'] = str(y_train.dtype)\n",
                "answer['X_valid.dtype'] = str(X_valid.dtype)\n",
                "answer['y_valid.dtype'] = str(y_valid.dtype)\n",
                "answer['X_train.shape'] = X_train.shape\n",
                "answer['X_valid.shape'] = X_valid.shape\n",
                "answer['y_train.shape'] = y_train.shape\n",
                "answer['y_valid.shape'] = y_valid.shape\n",
                "answer['X_train.mean'] = float(X_train.mean())\n",
                "answer['y_train.mean'] = float(y_train.float().mean())\n",
                "answer['X_valid.mean'] = float(X_valid.mean())\n",
                "answer['y_valid.mean'] = float(y_valid.float().mean())\n",
                "\n",
                "print(X_train.dtype, X_valid.dtype, y_train.dtype, y_valid.dtype)\n",
                "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
                "\n",
                "print(X_train)\n",
                "print(X_valid)\n",
                "print(y_train)\n",
                "print(y_valid)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 365
                },
                "colab_type": "code",
                "id": "Z1tFXMwJpS3e",
                "outputId": "e7c2778b-d6f5-4718-ea28-fc8544f0416c"
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "plt.imshow(X_train)\n",
                "plt.show()\n",
                "print(y_train)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Build the code for the network"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This time we will build an autoencoder network that contains two parts:\n",
                "- Encoder\n",
                "- Decoder\n",
                "\n",
                "Your task will be to build a model that contains two of these modules (each Fully-Connected Neural Network) having in mind that volume of Encoder should be exactly equal to the volume of the decoder.\n",
                "\n",
                "Both encoder and decoder should have the same structure:\n",
                "```bash\n",
                "Linear\n",
                "Activation\n",
                "Linear     x N\n",
                "Activation x N\n",
                "Linear\n",
                "```\n",
                "\n",
                "Number of linear and activation layers should be taken from the input list of channels.\n",
                "\n",
                "For instance, if the list with channels is `[28*28, 128, 64]`, the encoder should look like:\n",
                "```\n",
                "28 * 28 -> Linear -> Activation -> 128 -> Linear -> Activation -> 64 -> Linear -> 64\n",
                "```\n",
                "\n",
                "The decoder should look like:\n",
                "```\n",
                "28 * 28 <- Linear <- 128 <- Activation <- Linear <- 64 <- Activation <- Linear <- 64\n",
                "```\n",
                "\n",
                "In this case the image is compressed into a vector of size 64"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = src.models.feedforward.autoencoder.Autoencoder([28 * 28, 128, 64])\n",
                "\n",
                "src.utils.deterministic_init(model)\n",
                "\n",
                "check_input = {'image': torch.randn(10, 28 * 28)}\n",
                "check_output = model(check_input['image'])\n",
                "\n",
                "answer['check_result'] = src.utils.detach_copy(check_output)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Create loss function and optimizer\n",
                "\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this case we will use Adam with standard parameters as optimizer (`lr=1.0e-4` and weight decay `1.0e-4`)\n",
                "\n",
                "As a loss function we will use MAE loss:\n",
                "\n",
                "$L(\\mathbf x^*, \\mathbf x) = \\sum_{s=1}^S |x^*_s - x^s|,$\n",
                "\n",
                "where index $s$ runs through all the pixels of all images (predicted and input)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "00_2j2igpS3o"
            },
            "outputs": [],
            "source": [
                "import torchmetrics\n",
                "\n",
                "\n",
                "def loss(pred, targ):\n",
                "    val = 0\n",
                "    ## YOUR CODE HERE\n",
                "    return val\n",
                "\n",
                "epochs = 10\n",
                "\n",
                "optimizer = ...\n",
                "\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "answer['optimizer'] = str(optimizer)\n",
                "\n",
                "print(optimizer)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Create DataLoaders"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "wZtqiGvfpS3r"
            },
            "outputs": [],
            "source": [
                "from tqdm import trange, tqdm\n",
                "import neptune\n",
                "import os\n",
                "\n",
                "batch_size = 32\n",
                "n_epochs = 10\n",
                "\n",
                "train_dl = ...\n",
                "valid_dl = ...\n",
                "\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 5: Create training loop"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Firstly, we will use a service that allows to share the training reports. I strongly recommend using mlflow for your experiments, but for the sake of being able to share the results, we will use [neptune.ai](https://neptune.ai/)\n",
                "\n",
                "Create an account there, create your first experiment (and name it something like `MNIST FCNN`)\n",
                "\n",
                "Then create run with `neptune.ai` in your code.\n",
                "\n",
                "After that you will be able to see on that website the flow of your experiment.\n",
                "\n",
                "Then it is time to create the training cycle.\n",
                "\n",
                "Training cycles usually are custom for every network, because of that we will not create one for all the cases.\n",
                "\n",
                "Training cycles run in epochs each containing 2 stages:\n",
                "- training\n",
                "- validation\n",
                "\n",
                "Here is what you should do in the training stage:\n",
                "1. extract training batch from training dataloader\n",
                "2. switch the network to training state (`model.train()`)(will be important for batchnorms and some other modules)\n",
                "2. generate predictions from the training inputs using the model (`model(inputs)`)\n",
                "3. calculate the value of the loss that compares the predictions to the targets\n",
                "4. perform backpropagation (`loss_val.backward()`)\n",
                "5. make optimization step  with optimizer (`optimizer.step()`)\n",
                "6. reset optimizer's gradients (`optimizer.zero_grad()`)\n",
                "7. switch the network to validation state (`model.eval()`)\n",
                "8. evaluate training the accuracy of your model and update metrics that keep track of accuracy and loss (averaged throughout the training step)\n",
                "\n",
                "This should be done in iterations for all training batches that come out from `train_dl`\n",
                "\n",
                "Note that it is extremely important to do `detach` when you memorize accuracy and loss values so that after each iteration RAM is freed automatically by pytorch (because in case we plan to perform backprop, all the intermediate values are needed, and cannot be freed).\n",
                "\n",
                "Once in a while, if you experience RAM leakage, you should make sure that you detach metrics and loss values that you memorize. In case that does not help, delete all the variables manually and after that call pythons's garbage collector (`gc.collect()`). This will help pytorch with cleaning RAM.\n",
                "\n",
                "If you do not want to think about detaching and other aspects of graph backpropagation in some part of your code, you may use `torch.no_grad()` context. Exactly that statement we will use during validation stage of the cycle. This context also can be used as a decorator of a function that does not require gradient propagation.\n",
                "\n",
                "Now it is time to do validation:\n",
                "- make prediction for validation data\n",
                "- calculate accuracy for the predictions for both sets\n",
                "- calculate loss function for the predictions for both sets\n",
                "\n",
                "Note that the code should look very similarly to training cycle. The only difference is that this time we do not perform backpropagation and optimizer step.\n",
                "\n",
                "By the end of each epoch, submit the report about accuracies that you gotten and loss values to neptune.ai (run['losses/loss_value/train'].log(train_loss_value))"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer):\n",
                "    train_loss_history = []\n",
                "    valid_loss_history = []\n",
                "\n",
                "    ## YOU SHOULD ADD THE nepune.ai TOKEN BEFORE RUNNING THE TRAINING\n",
                "    run = neptune.init_run(\n",
                "        ## YOUR CODE HERE\n",
                "    )\n",
                "\n",
                "    for epoch in range(n_epochs):\n",
                "        train_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "        valid_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "\n",
                "        for batch in tqdm(train_dl):\n",
                "            ...\n",
                "            ## YOUR TRAINING CODE HERE\n",
                "\n",
                "        with torch.no_grad():\n",
                "            for valid_batch in tqdm(valid_dl):\n",
                "                ...\n",
                "                ## YOUR EVALUATION CODE HERE\n",
                "\n",
                "            finalized_train_loss = train_loss['enumerator'] / train_loss['denominator']\n",
                "            finalized_valid_loss = valid_loss['enumerator'] / valid_loss['denominator']\n",
                "\n",
                "            # Logging the progress to neptune\n",
                "\n",
                "            train_loss_history.append(finalized_train_loss)\n",
                "            valid_loss_history.append(finalized_valid_loss)\n",
                "\n",
                "    run.stop()\n",
                "    return train_loss_history, valid_loss_history\n",
                "\n",
                "train_loss_history, valid_loss_history = train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "answer['train_loss_history'] = train_loss_history\n",
                "answer['valid_loss_history'] = valid_loss_history\n",
                "\n",
                "json_tricks.dump(answer, '.answer.json')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 7. Experiment time!"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a new autoencoder model and train it for 100 epochs (or more if you like)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_epochs = 150\n",
                "model = src.models.feedforward.autoencoder.Autoencoder([28 * 28, 128, 64])\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3, weight_decay=1.0e-8)\n",
                "\n",
                "train_loss_history, valid_loss_history = train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    img1 = MNIST_valid[0]['image']\n",
                "    img2 = MNIST_valid[1]['image']\n",
                "\n",
                "    plt.figure()\n",
                "    plt.imshow(img1.reshape([28, 28]))\n",
                "    plt.figure()\n",
                "    plt.imshow(img2.reshape([28, 28]))\n",
                "\n",
                "    emb1 = model.encoder(img1.reshape([1, -1]))\n",
                "    emb2 = model.encoder(img2.reshape([1, -1]))\n",
                "\n",
                "    rec1 = model.decoder(emb1)\n",
                "    rec2 = model.decoder(emb2)\n",
                "\n",
                "    plt.figure()\n",
                "    plt.imshow(rec1.reshape([28, 28]))\n",
                "    plt.figure()\n",
                "    plt.imshow(rec2.reshape([28, 28]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    for a in np.linspace(0, 1, 10):\n",
                "        plt.figure()\n",
                "        rec = model.decoder(a * emb1 + (1 - a) * emb2)\n",
                "        plt.imshow(rec.reshape([28, 28]))\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "Lesson 5 Digits Recognition Video.ipynb",
            "provenance": [],
            "version": "0.3.2"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}