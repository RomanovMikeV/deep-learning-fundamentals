{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The following lines enable automatic reloading of modules in an IPython/Jupyter environment.\n",
                "# They work exactly like the commented lines below, but avoid errors when not running in such an environment.\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n",
                "\n",
                "try:\n",
                "    # Only defined inside IPython/Jupyter\n",
                "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
                "    get_ipython().run_line_magic(\"autoreload\", \"2\")\n",
                "except (NameError, AttributeError):\n",
                "    # Not running in IPython â†’ just ignore\n",
                "    pass\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initializing answer variable\n",
                "answer = {}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "DWr6cvb9pS3J"
            },
            "outputs": [],
            "source": [
                "# Some libs that we will use\n",
                "import torch\n",
                "import random\n",
                "import numpy as np\n",
                "import json_tricks\n",
                "import lovely_tensors as lt\n",
                "\n",
                "# Making tensor printouts better\n",
                "lt.monkey_patch()\n",
                "\n",
                "# Adding sources to the pythonpath\n",
                "import sys\n",
                "root_path = '../../../..'\n",
                "sys.path.append(root_path)\n",
                "\n",
                "import dotenv\n",
                "dotenv.load_dotenv(dotenv.find_dotenv(root_path + '/.env'))\n",
                "\n",
                "# Importing sources of our project\n",
                "import src\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 0: Prepare the environment\n",
                "\n",
                "(Take care of reproducibility)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 1: Prepare the data"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will use the same MNIST dataset, so just import it"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "MqGQWTDIpS3R"
            },
            "outputs": [],
            "source": [
                "MNIST_train = ...\n",
                "MNIST_valid = ...\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check that the data is prepared:"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "vv_Lz7PYpS3U"
            },
            "outputs": [],
            "source": [
                "train_sample = MNIST_train[0]\n",
                "valid_sample = MNIST_valid[0]\n",
                "\n",
                "X_train = train_sample['image']\n",
                "X_valid = valid_sample['image']\n",
                "y_train = train_sample['label']\n",
                "y_valid = valid_sample['label']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 35
                },
                "colab_type": "code",
                "id": "hMhsAedlrQF5",
                "outputId": "ae08bd21-79ff-48da-9886-48996a178110"
            },
            "outputs": [],
            "source": [
                "## This checks are for dataset verification\n",
                "answer['X_train.dtype'] = str(X_train.dtype)\n",
                "answer['y_train.dtype'] = str(y_train.dtype)\n",
                "answer['X_valid.dtype'] = str(X_valid.dtype)\n",
                "answer['y_valid.dtype'] = str(y_valid.dtype)\n",
                "answer['X_train.shape'] = X_train.shape\n",
                "answer['X_valid.shape'] = X_valid.shape\n",
                "answer['y_train.shape'] = y_train.shape\n",
                "answer['y_valid.shape'] = y_valid.shape\n",
                "answer['X_train.mean'] = float(X_train.mean())\n",
                "answer['y_train.mean'] = float(y_train.float().mean())\n",
                "answer['X_valid.mean'] = float(X_valid.mean())\n",
                "answer['y_valid.mean'] = float(y_valid.float().mean())\n",
                "\n",
                "print(X_train.dtype, X_valid.dtype, y_train.dtype, y_valid.dtype)\n",
                "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
                "\n",
                "print(X_train)\n",
                "print(X_valid)\n",
                "print(y_train)\n",
                "print(y_valid)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 365
                },
                "colab_type": "code",
                "id": "Z1tFXMwJpS3e",
                "outputId": "e7c2778b-d6f5-4718-ea28-fc8544f0416c"
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "plt.imshow(X_train)\n",
                "plt.show()\n",
                "print(y_train)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Build the code for the Autoencoder"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This time we will build an autoencoder network that contains two parts:\n",
                "- Encoder\n",
                "- Decoder\n",
                "\n",
                "Your task will be to build a model that contains two of these modules (each Fully-Connected Neural Network) having in mind that volume of Encoder should be exactly equal to the volume of the decoder.\n",
                "\n",
                "Both encoder and decoder should have the same structure:\n",
                "```bash\n",
                "Linear\n",
                "Activation\n",
                "Linear     x N\n",
                "Activation x N\n",
                "Linear\n",
                "```\n",
                "\n",
                "The code should be done in `src/models/feedforward/autoencoders.py`\n",
                "\n",
                "Number of linear and activation layers should be taken from the input list of channels.\n",
                "\n",
                "For instance, if the list with channels is `[28*28, 128, 64]`, the encoder should look like:\n",
                "```\n",
                "28 * 28 -> Linear -> Activation -> 128 -> Linear -> Activation -> 64 -> Linear -> 64\n",
                "```\n",
                "\n",
                "The decoder should look like:\n",
                "```\n",
                "28 * 28 <- Linear <- 128 <- Activation <- Linear <- 64 <- Activation <- Linear <- 64\n",
                "```\n",
                "\n",
                "In this case the image is compressed into a vector of size 64"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Load your Autoencoder model\n",
                "model = src.models.feedforward.autoencoder.Autoencoder([28 * 28, 128, 64])\n",
                "\n",
                "# Init the model for checking\n",
                "src.utils.deterministic_init(model)\n",
                "\n",
                "\n",
                "check_input = {'image': torch.randn(10, 28 * 28)}\n",
                "with torch.no_grad():\n",
                "    check_output = model(check_input['image'])\n",
                "\n",
                "    answer['check_result'] = src.utils.detach_copy(check_output)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Build Variational Autoencoder"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The main difference between standard AutoEncoder and Variational AutoEncoder is that in Variational Autoencoder there is a reparametrization block (we will call it `sampler` in our network)\n",
                "\n",
                "The idea is that this block computes $\\mu$ and $\\sigma$ from the input signal, and then samples the result from $\\mathcal N (\\mu, \\sigma)$\n",
                "\n",
                "Your task is to code this block.\n",
                "\n",
                "Use linear layers to predict a tensor of $\\mu$ and a tensor used to calculate $\\sigma$ (without activation): $\\mathbf z_\\mu$, $\\mathbf z_{\\sigma}$\n",
                "- `mu_regressor`\n",
                "- `logvar_regressor`\n",
                "\n",
                "After that, calculate:\n",
                "- $\\mu = \\mathbf z_{\\mu}$\n",
                "- $\\sigma = \\exp(\\frac{1}{2} \\mathbf z_{\\sigma})$\n",
                "\n",
                "In the end, you should calculate the result as\n",
                "- In case of training mode:\n",
                "    $\\mathbf z_{out} = \\mu + \\mathbf \\epsilon * \\sigma,$ where $\\epsilon \\propto \\mathcal N (0, 1)$\n",
                "- In case of evaluation mode:\n",
                "    $\\mathbf z_{out} = \\mu$\n",
                "\n",
                "Note that all the tensors, $\\mu$, $\\sigma$ and $\\epsilon$ should have the same shape as the input tensor.\n",
                "\n",
                "Add the abovecreated block in the middle of your Autoencoder to get VAE."
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Load your VAE model\n",
                "model = src.models.feedforward.autoencoder.VAE([28 * 28, 128, 64])\n",
                "\n",
                "# Init the model for checking\n",
                "src.utils.deterministic_init(model)\n",
                "\n",
                "\n",
                "check_input = {'image': torch.randn(10, 28 * 28)}\n",
                "with torch.no_grad():\n",
                "    check_output = model(check_input['image'])\n",
                "\n",
                "    answer['check_result'] = src.utils.detach_copy(check_output)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Create loss function and optimizer\n",
                "\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this case we will use Adam with standard parameters as optimizer (`lr=1.0e-4` and weight decay `1.0e-4`)\n",
                "\n",
                "As a loss function we will use MAE loss:\n",
                "\n",
                "$L(\\mathbf x^*, \\mathbf x) = \\frac{1}{S}\\sum_{s=1}^S |x^*_s - x^s|,$\n",
                "\n",
                "where index $s$ runs through all the pixels of all images (predicted and input)\n",
                "\n",
                "Also create yet another loss function for regularization of the Variational AutoEncoder (VAE)\n",
                "\n",
                "It works like this:\n",
                "\n",
                "$L_{reg} = \\frac{1}{2S}\\sum_{s=1}^{S} (\\mu_s^2 + \\sigma_s^2 - \\log \\sigma_s^2 - 1)$\n",
                "\n",
                "(this value is KL distance beteween normal distribution $\\mathcal N (0, 1)$ and $\\mathcal N (\\mu_s, \\sigma_s)$). What we are doing is we are training the model so that it minimizes the loss above, but does not deviate too much from univariate normal distribution."
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "00_2j2igpS3o"
            },
            "outputs": [],
            "source": [
                "import torchmetrics\n",
                "\n",
                "\n",
                "def loss(pred, targ):\n",
                "    val = 0\n",
                "    ## YOUR CODE HERE\n",
                "    return val\n",
                "\n",
                "epochs = 10\n",
                "\n",
                "optimizer = ...\n",
                "\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Checking loss\n",
                "answer['loss_val'] = loss(torch.randn(5, 28, 28), torch.randn(5, 28, 28))\n",
                "\n",
                "# Adding optimizer to the checker\n",
                "answer['optimizer'] = str(optimizer)\n",
                "print(optimizer)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Create DataLoaders"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "wZtqiGvfpS3r"
            },
            "outputs": [],
            "source": [
                "from tqdm import trange, tqdm\n",
                "import neptune\n",
                "import os\n",
                "\n",
                "batch_size = 32\n",
                "n_epochs = 10\n",
                "\n",
                "train_dl = ...\n",
                "valid_dl = ...\n",
                "\n",
                "## YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 5: Create training loop"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The task is the same:\n",
                "- load samples batch-by-batch\n",
                "- send the smaples through the model\n",
                "- calculate loss function\n",
                "- backpropagate the gradient\n",
                "- step the optimizer\n",
                "- perform validation to check overfitting"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer):\n",
                "    train_loss_history = []\n",
                "    valid_loss_history = []\n",
                "\n",
                "    ## YOU SHOULD ADD THE nepune.ai TOKEN BEFORE RUNNING THE TRAINING\n",
                "    run = neptune.init_run(\n",
                "        ## YOUR CODE HERE\n",
                "    )\n",
                "\n",
                "    for epoch in range(n_epochs):\n",
                "        train_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "        valid_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "\n",
                "        for batch in tqdm(train_dl):\n",
                "            ...\n",
                "            ## YOUR TRAINING CODE HERE\n",
                "\n",
                "        with torch.no_grad():\n",
                "            for valid_batch in tqdm(valid_dl):\n",
                "                ...\n",
                "                ## YOUR EVALUATION CODE HERE\n",
                "\n",
                "            finalized_train_loss = train_loss['enumerator'] / train_loss['denominator']\n",
                "            finalized_valid_loss = valid_loss['enumerator'] / valid_loss['denominator']\n",
                "\n",
                "            # Logging the progress to neptune\n",
                "\n",
                "            train_loss_history.append(finalized_train_loss)\n",
                "            valid_loss_history.append(finalized_valid_loss)\n",
                "\n",
                "    run.stop()\n",
                "    return train_loss_history, valid_loss_history\n",
                "\n",
                "train_loss_history, valid_loss_history = train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "answer['train_loss_history'] = train_loss_history\n",
                "answer['valid_loss_history'] = valid_loss_history\n",
                "\n",
                "json_tricks.dump(answer, '.answer.json')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 7. Experiment time!"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a new autoencoder model and train it for 100 epochs (or more if you like)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_epochs = 150\n",
                "model = src.models.feedforward.autoencoder.Autoencoder([28 * 28, 128, 64])\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3, weight_decay=1.0e-8)\n",
                "\n",
                "train_loss_history, valid_loss_history = train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    img1 = MNIST_valid[0]['image']\n",
                "    img2 = MNIST_valid[1]['image']\n",
                "\n",
                "    plt.figure()\n",
                "    plt.imshow(img1.reshape([28, 28]))\n",
                "    plt.figure()\n",
                "    plt.imshow(img2.reshape([28, 28]))\n",
                "\n",
                "    emb1 = model.encoder(img1.reshape([1, -1]))\n",
                "    emb2 = model.encoder(img2.reshape([1, -1]))\n",
                "\n",
                "    rec1 = model.decoder(emb1)\n",
                "    rec2 = model.decoder(emb2)\n",
                "\n",
                "    plt.figure()\n",
                "    plt.imshow(rec1.reshape([28, 28]))\n",
                "    plt.figure()\n",
                "    plt.imshow(rec2.reshape([28, 28]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "figures = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for a in np.linspace(0, 1, 10):\n",
                "        rec = model.decoder(a * emb1 + (1 - a) * emb2)\n",
                "        figures.append(rec)\n",
                "\n",
                "plt.imshow(np.concatenate(figures, axis=1))\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "Lesson 5 Digits Recognition Video.ipynb",
            "provenance": [],
            "version": "0.3.2"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}